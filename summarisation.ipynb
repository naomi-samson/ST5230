{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          note_id  subject_id     hadm_id note_type  note_seq  \\\n",
      "0  10000032-RR-14    10000032  22595853.0        RR        14   \n",
      "1  10000032-RR-15    10000032  22595853.0        RR        15   \n",
      "2  10000032-RR-16    10000032  22595853.0        RR        16   \n",
      "3  10000032-RR-18    10000032         NaN        RR        18   \n",
      "4  10000032-RR-20    10000032         NaN        RR        20   \n",
      "\n",
      "             charttime            storetime   Examination  \\\n",
      "0  2180-05-06 21:19:00  2180-05-06 23:32:00         CHEST   \n",
      "1  2180-05-06 23:00:00  2180-05-06 23:26:00         LIVER   \n",
      "2  2180-05-07 09:55:00  2180-05-07 11:15:00           NaN   \n",
      "3  2180-06-03 12:46:00  2180-06-03 14:01:00    Ultrasound   \n",
      "4  2180-07-08 13:18:00  2180-07-08 14:15:00  Paracentesis   \n",
      "\n",
      "                                          Indication  \\\n",
      "0      with new onset ascites  // eval for infection   \n",
      "1          year-old female with cirrhosis, jaundice.   \n",
      "2   HCV cirrhosis c/b ascites, hiv on ART, h/o IV...   \n",
      "3   year old woman with cirrhosis, ascites despit...   \n",
      "4   year old woman with cirrhosis, ascites despit...   \n",
      "\n",
      "                                           Technique             Comparison  \\\n",
      "0                               Chest PA and lateral                  None.   \n",
      "1  Grey scale and color Doppler ultrasound images...                  None.   \n",
      "2  Ultrasound guided diagnostic and therapeutic p...  Abdominal ultrasound    \n",
      "3         Ultrasound guided therapeutic paracentesis                      .   \n",
      "4         Ultrasound guided therapeutic paracentesis       Paracentesis on    \n",
      "\n",
      "                                            Findings  \\\n",
      "0  There is no focal consolidation, pleural effus...   \n",
      "1  LIVER: The liver is coarsened and nodular in e...   \n",
      "2  Limited grayscale ultrasound imaging of the ab...   \n",
      "3  Limited grayscale ultrasound imaging of the ab...   \n",
      "4  Limited grayscale ultrasound imaging of the ab...   \n",
      "\n",
      "                                          Impression  \\\n",
      "0                  No acute cardiopulmonary process.   \n",
      "1  1. Nodular appearance of the liver compatible ...   \n",
      "2  Successful uncomplicated ultrasound guided dia...   \n",
      "3  Uneventful therapeutic paracentesis yielding 1...   \n",
      "4  4.75 L of slightly cloudy, blood tinged fluid ...   \n",
      "\n",
      "                                       combined_text  \\\n",
      "0  CHEST  with new onset ascites  // eval for inf...   \n",
      "1  LIVER  year-old female with cirrhosis, jaundic...   \n",
      "2  nan  HCV cirrhosis c/b ascites, hiv on ART, h/...   \n",
      "3  Ultrasound  year old woman with cirrhosis, asc...   \n",
      "4  Paracentesis  year old woman with cirrhosis, a...   \n",
      "\n",
      "                                      tokenized_text Gender  \n",
      "0  ['chest', 'new', 'onset', 'ascites', 'eval', '...    NaN  \n",
      "1  ['liver', 'female', 'cirrhosis', 'jaundice', '...      F  \n",
      "2  ['hcv', 'cirrhosis', 'c', 'b', 'ascites', 'hiv...    NaN  \n",
      "3  ['ultrasound', 'woman', 'cirrhosis', 'ascites'...      F  \n",
      "4  ['paracentesis', 'woman', 'cirrhosis', 'ascite...      F  \n",
      "Index(['note_id', 'subject_id', 'hadm_id', 'note_type', 'note_seq',\n",
      "       'charttime', 'storetime', 'Examination', 'Indication', 'Technique',\n",
      "       'Comparison', 'Findings', 'Impression', 'combined_text',\n",
      "       'tokenized_text', 'Gender'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Preprocessed_radiology_data.xls\")\n",
    "print(df.head())\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHEST  with new onset ascites  // eval for infection Chest PA and lateral None. There is no focal consolidation, pleural effusion or pneumothorax.  Bilateral No acute cardiopulmonary process.\n",
      "['chest', 'new', 'onset', 'ascites', 'eval', 'infection', 'chest', 'pa', 'lateral', 'focal', 'consolidation', 'pleural', 'effusion', 'pneumothorax', 'bilateral', 'acute', 'cardiopulmonary', 'process']\n"
     ]
    }
   ],
   "source": [
    "print(df.combined_text[0])\n",
    "print(df.tokenized_text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " There is no focal consolidation, pleural effusion or pneumothorax. CHEST  with new onset ascites  // eval for infection Chest PA and lateral None.   Bilateral No acute cardiopulmonary process\n"
     ]
    }
   ],
   "source": [
    "def extractive_tfidf_summary(text, num_sentences=3):\n",
    "    # Split the text into sentences\n",
    "    sentences = text.split('.')\n",
    "    \n",
    "    # Initialize TF-IDF Vectorizer\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = vectorizer.fit_transform(sentences)\n",
    "    \n",
    "    # Calculate cosine similarity between sentences\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix)\n",
    "    \n",
    "    # Sum the cosine similarity scores for each sentence\n",
    "    sentence_scores = cosine_sim.sum(axis=1)\n",
    "    \n",
    "    # Get indices of the top N sentences\n",
    "    top_sentence_indices = sentence_scores.argsort()[-num_sentences:][::-1]\n",
    "    \n",
    "    # Select and return the top sentences\n",
    "    summary = '. '.join([sentences[i] for i in top_sentence_indices])\n",
    "    return summary\n",
    "\n",
    "# Example: Apply to one of the combined texts\n",
    "example_text = df['combined_text'][0]\n",
    "summary_tfidf = extractive_tfidf_summary(example_text)\n",
    "print(summary_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flesch-Kincaid Grade Level: 11.5\n",
      "SMOG Index: 11.9\n"
     ]
    }
   ],
   "source": [
    "# Compute readability scores for the summary\n",
    "fk_score = textstat.flesch_kincaid_grade(summary_tfidf)\n",
    "smog_score = textstat.smog_index(summary_tfidf)\n",
    "\n",
    "print(\"Flesch-Kincaid Grade Level:\", fk_score)\n",
    "print(\"SMOG Index:\", smog_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Summary:\n",
      " CHEST  with new onset ascites  // eval for infection Chest PA and lateral None.\n",
      "There is no focal consolidation, pleural effusion or pneumothorax.  \n",
      "Bilateral No acute cardiopulmonary process.\n"
     ]
    }
   ],
   "source": [
    "import pytextrank\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Add PyTextRank to the pipeline\n",
    "nlp.add_pipe(\"textrank\")\n",
    "\n",
    "# Define your text (e.g., clinical notes or any long text)\n",
    "text = df['combined_text'][0]\n",
    "\n",
    "# Process the text using spaCy\n",
    "doc = nlp(text)\n",
    "\n",
    "# Extract the top sentences based on PyTextRank's ranking\n",
    "top_sentences = []\n",
    "for sent in doc._.textrank.summary(limit_phrases=15, limit_sentences=5):\n",
    "    top_sentences.append(sent.text)\n",
    "\n",
    "# Print the extracted summary\n",
    "summary_textrank = \"\\n\".join(top_sentences)\n",
    "print(\"Extracted Summary:\\n\", summary_textrank)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flesch-Kincaid Grade Level: 11.5\n",
      "SMOG Index: 11.9\n"
     ]
    }
   ],
   "source": [
    "# Compute readability scores for the summary\n",
    "fk_score = textstat.flesch_kincaid_grade(summary_textrank)\n",
    "smog_score = textstat.smog_index(summary_textrank)\n",
    "\n",
    "print(\"Flesch-Kincaid Grade Level:\", fk_score)\n",
    "print(\"SMOG Index:\", smog_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there is no focal consolidation, pleural effusion or pneumothorax.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# Load the pre-trained T5 model and tokenizer\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "\n",
    "def abstractive_t5_summary(text):\n",
    "    # Encode the input text and generate the output\n",
    "    input_text = f\"summarize: {text}\"\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt', max_length=512, truncation=True)\n",
    "    \n",
    "    # Generate summary\n",
    "    summary_ids = model.generate(input_ids, max_length=150, num_beams=4, early_stopping=True)\n",
    "    \n",
    "    # Decode the summary\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Example: Apply to one of the combined texts\n",
    "summary_t5 = abstractive_t5_summary(example_text)\n",
    "print(summary_t5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flesch-Kincaid Grade Level: 13.9\n",
      "SMOG Index: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Compute readability scores for the summary\n",
    "fk_score = textstat.flesch_kincaid_grade(summary_t5)\n",
    "smog_score = textstat.smog_index(summary_t5)\n",
    "\n",
    "print(\"Flesch-Kincaid Grade Level:\", fk_score)\n",
    "print(\"SMOG Index:\", smog_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clinical T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clinical-T5 Scratch model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "model_path = \"C:/Users/naomi/physionet.org/files/clinical-t5/1.0.0/Clinical-T5-Scratch\"\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "\n",
    "print(\"Clinical-T5 Scratch model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T5 from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: eval for infection Chest PA and lateral None. There is no focal consolidation, pleural effusion or pneumothorax. Bilateral No acute cardiopulmonary process.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "\n",
    "# Example text (replace with your combined_text)\n",
    "text = df['combined_text'][0]\n",
    "\n",
    "# Prepare the text\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True, padding=True)\n",
    "\n",
    "# Generate summary\n",
    "summary_ids = model.generate(inputs[\"input_ids\"], max_length=100, num_beams=4, early_stopping=True)\n",
    "\n",
    "# Decode the summary\n",
    "summary_t5scratch = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "print(f\"Summary: {summary_t5scratch}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flesch-Kincaid Grade Level: 13.2\n",
      "SMOG Index: 11.9\n"
     ]
    }
   ],
   "source": [
    "# Compute readability scores for the summary\n",
    "fk_score = textstat.flesch_kincaid_grade(summary_t5scratch)\n",
    "smog_score = textstat.smog_index(summary_t5scratch)\n",
    "\n",
    "print(\"Flesch-Kincaid Grade Level:\", fk_score)\n",
    "print(\"SMOG Index:\", smog_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Small fine-tuned T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"dlyog/t5-small-finetuned\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"dlyog/t5-small-finetuned\")\n",
    "\n",
    "def summarize(text):\n",
    "    input_text = \"summarize: \" + text\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "    summary_ids = model.generate(input_ids)\n",
    "    summary = tokenizer.decode(summary_ids[0])\n",
    "    return summary\n",
    "\n",
    "# Example usage\n",
    "summary = summarize(df['combined_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flesch-Kincaid Grade Level: 13.2\n",
      "SMOG Index: 11.9\n"
     ]
    }
   ],
   "source": [
    "# Compute readability scores for the summary\n",
    "fk_score = textstat.flesch_kincaid_grade(summary_t5scratch)\n",
    "smog_score = textstat.smog_index(summary_t5scratch)\n",
    "\n",
    "print(\"Flesch-Kincaid Grade Level:\", fk_score)\n",
    "print(\"SMOG Index:\", smog_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
